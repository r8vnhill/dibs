---
title: Property-Based Testing
---
import ReadingTime from '@site/src/components/ReadingTime'
import { ProCons, Pros, Cons } from '@site/src/components/cajitas/ProCons'
import References from '@site/src/components/ReferencesComponent'
import Tabs from '@theme/Tabs'
import TabItem from '@theme/TabItem'
import Exercise from '@site/src/components/exercise/Exercise'
import Solution from '@site/src/components/exercise/Solution'
import Hint from '@site/src/components/exercise/Hint'
import Definition from '@site/src/components/Definition'
import Corollary from '@site/src/components/Corollary'
import GithubRepoLink from '@site/src/components/git/GithubRepoLink'
import { LanguageCard } from '@site/src/components/cards/LanguageCard'
import Explanation from '@site/src/components/admonitions/Explanation'
import RepoClone from '@site/src/components/admonitions/RepoClone'
import BoxedTabs from '@site/src/components/cajitas/BoxedTabs'

<ReadingTime />
<GithubRepoLink repo={"property-based-testing-kt"} user={"r8vnhill"}/>
<RepoClone repoName="property-based-testing-kt" />

## Testeando la función `merge`

Imaginemos que queremos testear la función `merge`, la cual toma dos listas ordenadas como entrada y devuelve una nueva lista que contiene todos los elementos de ambas listas, manteniendo el orden.

### ¿Cómo podríamos probar esta función?

Podríamos recurrir a **Data-Driven Testing** para verificar su comportamiento. Esto implicaría definir varios conjuntos de datos de entrada y validar que la función produce los resultados esperados para cada uno. Sin embargo, ¿qué conjuntos de datos serían apropiados para cubrir todos los casos posibles?

### Preguntas clave al elegir inputs

1. ¿Qué ocurre si una o ambas listas están vacías?
2. ¿Qué pasa cuando las listas tienen elementos repetidos?
3. ¿Cómo se comporta `merge` cuando una lista contiene elementos mayores o menores que todos los de la otra?
4. ¿Qué sucede si ambas listas ya están ordenadas pero con diferentes rangos de valores?

### Ejemplo de inputs que podríamos usar

- `merge([], [])` → `[]` (Ambas listas vacías)
- `merge([1, 3, 5], [])` → `[1, 3, 5]` (Una lista vacía)
- `merge([], [2, 4, 6])` → `[2, 4, 6]` (Otra lista vacía)
- `merge([1, 3], [2, 4])` → `[1, 2, 3, 4]` (Listas con valores intercalados)
- `merge([1, 2, 3], [4, 5, 6])` → `[1, 2, 3, 4, 5, 6]` (Una lista con valores completamente menores)
- `merge([2, 4, 6], [1, 3, 5])` → `[1, 2, 3, 4, 5, 6]` (Listas desordenadas entre sí)

### Definición de los Casos de Prueba con `withData`

A continuación, definimos los casos de prueba usando la estructura `FreeSpec` y la función `withData`, lo que permite pasar múltiples casos de prueba de forma concisa y ejecutar la misma lógica sobre diferentes inputs.

<BoxedTabs>
    <TabItem label={"Código esencial"} value={"Código esencial"}>
        ```kotlin showLineNumbers title="type-fundamentals/src/test/kotlin/com/github/username/merge/MergeTest.kt"
        withData(
            Triple(listOf(), listOf(), listOf()),
            Triple(listOf(1), listOf(), listOf(1)),
            Triple(listOf(), listOf(1), listOf(1)),
            Triple(listOf(1), listOf(1), listOf(1, 1)),
            Triple(listOf(1, 2), listOf(1), listOf(1, 1, 2)),
            Triple(listOf(1), listOf(1, 2), listOf(1, 1, 2)),
            Triple(listOf(1, 3), listOf(2, 4), listOf(1, 2, 3, 4)),
            Triple(listOf(1, 2, 3), listOf(4, 5, 6), listOf(1, 2, 3, 4, 5, 6))
        ) { (list1, list2, expected) ->
            merge(list1, list2) shouldBe expected
        }
        ```
    </TabItem>
    <TabItem label={"Código completo"} value={"Código completo"}>
        ```kotlin showLineNumbers title="type-fundamentals/src/test/kotlin/com/github/username/merge/MergeTest.kt"
        package com.github.username.merge

        import io.kotest.core.spec.style.FreeSpec
        import io.kotest.datatest.withData
        import io.kotest.matchers.shouldBe

        class MergeTest : FreeSpec({
            "Merging two lists" - {
                "should return a list with all elements sorted" - {
                    withData(
                        MergeTestCase(listOf(), listOf(), listOf()),
                        MergeTestCase(listOf(1), listOf(), listOf(1)),
                        MergeTestCase(listOf(), listOf(1), listOf(1)),
                        MergeTestCase(listOf(1), listOf(1), listOf(1, 1)),
                        MergeTestCase(listOf(1, 2), listOf(1), listOf(1, 1, 2)),
                        MergeTestCase(listOf(1), listOf(1, 2), listOf(1, 1, 2)),
                        MergeTestCase(listOf(1, 3), listOf(2, 4), listOf(1, 2, 3, 4)),
                        MergeTestCase(listOf(1, 2, 3), listOf(4, 5, 6), listOf(1, 2, 3, 4, 5, 6)),
                    ) { (list1, list2, expected) ->
                        merge(list1, list2) shouldBe expected
                    }
                }
            }
        })

        private data class MergeTestCase(
            val list1: List<Int>,
            val list2: List<Int>,
            val expected: List<Int>
        )
        ```
    </TabItem>
</BoxedTabs>

## El Desafío del Data-Driven Testing

Aunque el **Data-Driven Testing** es una técnica poderosa para probar diferentes conjuntos de datos de manera sistemática, presenta algunos desafíos importantes:

<ProCons>
    <Cons>
        - **Mantenimiento y complejidad**: Requiere que quien desarrolla piense y defina manualmente todos los casos de prueba posibles. A medida que los escenarios crecen en complejidad, la cantidad de datos y la gestión de los mismos pueden volverse complicadas y propensas a errores.
        - **Dificultad para cumplir el Principio Open/Closed**: Si necesitamos agregar más casos de prueba, esto generalmente implica modificar directamente el código de prueba existente, lo que puede ir en contra del principio **Open/Closed** del diseño de software. Este principio establece que el código debe estar abierto a la extensión pero cerrado a la modificación. Cada vez que agregamos nuevos casos, estamos alterando el cuerpo de las pruebas, lo que aumenta el riesgo de introducir errores o inconsistencias.
    </Cons>
</ProCons>

### Posibles Soluciones

Una solución es utilizar **generación automática de datos de prueba** o emplear estrategias como el **property-based testing**, donde los casos se generan dinámicamente a partir de propiedades del sistema, reduciendo la necesidad de definir manualmente todos los casos y mejorando la capacidad de mantener el código de pruebas sin modificaciones constantes.

## Property-Based Testing (PBT)

El **Property-Based Testing** es una metodología de prueba en la que se definen propiedades generales sobre el comportamiento esperado de un programa. En lugar de escribir casos de prueba específicos, se especifican propiedades que deben cumplirse para cualquier conjunto de entradas, y el framework de PBT genera automáticamente una amplia variedad de datos de entrada para verificar dichas propiedades.

<ProCons>
    <Pros>
        - **Cobertura exhaustiva**: PBT permite probar una función contra miles de casos de prueba generados automáticamente, lo que aumenta la probabilidad de encontrar errores que podrían pasar desapercibidos con pruebas manuales o casos limitados.
        - **Detección temprana de errores**: Al probar con una gama extensa de entradas, PBT ayuda a descubrir errores en etapas tempranas del desarrollo.
        - **Enfoque en el comportamiento**: En lugar de enfocarse en casos específicos, PBT ayuda a definir y verificar el comportamiento general de un programa, asegurando que se cumpla bajo múltiples condiciones.
    </Pros>
    <Cons>
        - **Mayor complejidad inicial**: Escribir pruebas basadas en propiedades puede ser más complejo que los tests tradicionales, ya que se requiere una buena comprensión de las propiedades fundamentales del sistema que estamos probando.
    </Cons>
</ProCons>

:::tip

Aunque puede ser más difícil de implementar al principio, **Property-Based Testing** ofrece una poderosa alternativa al enfoque tradicional de **Data-Driven Testing**. Con su capacidad para generar numerosos casos de prueba automáticamente, PBT no solo mejora la cobertura y la robustez de las pruebas, sino que también contribuye a identificar fallos más rápidamente.

¡Considera usar PBT como una herramienta preferida frente a DDT en tus proyectos!

:::

### Propiedades en Property-Based Testing

A diferencia de los **tests tradicionales**, que dependen de casos de prueba específicos basados en ejemplos, las **propiedades** en Property-Based Testing definen condiciones generales que deben cumplirse sin importar los valores de entrada de la función.

- **Tests basados en ejemplos**: Verifican comportamientos en función de inputs específicos.
- **Testing basado en propiedades**: Las propiedades establecen afirmaciones generales sobre el comportamiento que siempre deben cumplirse, independientemente de los inputs. El testing basado en propiedades se enfoca en verificar estas propiedades en lugar de casos de prueba individuales.

#### Importancia de la Pureza de las Propiedades

Para que las propiedades sean efectivas y fiables en **Property-Based Testing**, es crucial que sean **propias** (**puras**). La **pureza** de una propiedad implica que:

1. **Determinismo**: Una propiedad pura siempre produce el mismo resultado dado el mismo input. No depende de estados externos ni de variables globales que puedan cambiar.
2. **Sin efectos secundarios**: Las propiedades puras no modifican el estado del sistema ni interactúan con el mundo exterior (por ejemplo, no realizan operaciones de I/O, no modifican bases de datos, etc.).
3. **Independencia**: Cada ejecución de una propiedad es independiente de las demás, lo que facilita la paralelización y evita interferencias entre pruebas.

<ProCons>
    <Pros>
        - **Reproducibilidad**: Si una prueba falla, es más fácil reproducir el error porque no hay estados externos que afecten el comportamiento.
        - **Facilidad de Mantenimiento**: Las propiedades puras son más simples de entender y mantener, ya que su comportamiento está completamente determinado por sus inputs.
        - **Eficiencia**: Al no depender de efectos secundarios, las propiedades puras pueden paralelizarse de forma segura, lo que mejora la eficiencia de las pruebas.
    </Pros>
</ProCons>

#### Generación Automática de Casos de Prueba

El **framework de testing** genera automáticamente una variedad de casos de prueba basados en las propiedades definidas. Este proceso se basa en múltiples condiciones y combinaciones de inputs, asegurando que la función cumpla con las expectativas bajo distintas circunstancias. Al enfocarse en propiedades puras, se garantiza que cada caso de prueba sea independiente y confiable, maximizando la efectividad del testing.

### Generadores arbitrarios

Los **generadores arbitrarios** son herramientas poderosas que permiten generar una gran variedad de entradas aleatorias para probar propiedades en los tests. En **Kotest**, existe una amplia gama de generadores prediseñados para diferentes tipos de datos, como enteros, cadenas, y colecciones, lo que facilita la creación de pruebas robustas con diversos escenarios de entrada.

Además, Kotest permite definir **generadores personalizados**, lo que brinda flexibilidad para casos de prueba más específicos y complejos. Estos generadores pueden componerse y transformarse, lo que los hace extremadamente versátiles para probar funciones bajo múltiples condiciones.

## ¿Qué aprendimos?

En esta lección exploramos dos enfoques fundamentales para el testing: **Data-Driven Testing (DDT)** y **Property-Based Testing (PBT)**. Ambos métodos nos ayudan a validar el comportamiento de nuestras funciones, pero tienen enfoques y beneficios distintos.

### Puntos clave

1. **Data-Driven Testing (DDT)** permite un control explícito sobre los inputs, pero puede ser difícil de mantener y escalar, ya que los casos de prueba deben definirse manualmente y el código de prueba puede volverse complejo.
2. **Property-Based Testing (PBT)** ofrece una alternativa poderosa al generar automáticamente casos de prueba, basándose en propiedades fundamentales del sistema bajo prueba. Aunque requiere más esfuerzo inicial para definir las propiedades, proporciona una cobertura mucho más exhaustiva y reduce la necesidad de mantener un gran número de casos de prueba predefinidos.
3. **Generadores Arbitrarios** son una herramienta clave en PBT para crear una variedad de inputs, lo que asegura que las propiedades se prueben bajo condiciones diversas y difíciles de prever manualmente.
4. **Propiedades puras** y su enfoque en el determinismo y la independencia de efectos secundarios garantizan que las pruebas sean fiables, reproducibles, y eficientes.

---

Al final, elegir entre DDT o PBT depende de las necesidades del proyecto. Si bien DDT es útil para pruebas controladas y específicas, PBT ofrece una ventaja considerable para pruebas exhaustivas y automatizadas, especialmente en funciones complejas o con muchas combinaciones de entradas posibles.

<References references={[
    {
        bookTitle: "Property-based testing with PropEr, Erlang, and Elixir: Find bugs before your users do",
        title: "Foundations of Property-Based Testing",
        publisher: "The Pragmatic Bookshelf",
        location: "Raleigh, North Carolina",
        pages: "3–16",
        type: "book",
        author: "Fred Hébert",
        year: "2019"
    },
]}/>

{/* Bibliografias por revisar */}
{/* ## 1. Property-Based Testing (PBT)  
Las **pruebas basadas en propiedades** son una técnica de testing automatizado situada entre la verificación formal mediante *model checking* y el *fuzzing* aleatorio ([Pruebas basadas en propiedades (i) – Lambda Violet](https://lambdaviolet.wordpress.com/2018/02/13/pruebas-basadas-en-propiedades-i/#:~:text=En%20un%20post%20anterior%2C%20mencionamos,t%C3%A9cnica%20de%20prueba%20completamente%20aleatoria)). En vez de escribir casos de prueba individuales (como en pruebas unitarias tradicionales), en PBT se definen *propiedades lógicas* que el software debe cumplir para **todos** los datos de entrada que coincidan con cierta especificación. El framework de pruebas genera entonces múltiples entradas aleatorias (cientos o miles) para verificar automáticamente dichas propiedades ([Comparativa de herramientas de pruebas basadas en propiedades para el lenguaje Python](https://ruc.udc.es/dspace/handle/2183/32825#:~:text=,tipo%20de%20datos%20a%20probar)) ([Pruebas basadas en propiedades (i) – Lambda Violet](https://lambdaviolet.wordpress.com/2018/02/13/pruebas-basadas-en-propiedades-i/#:~:text=En%20un%20punto%20intermedio%20entre,buena%20noticia%20es%20que%20las)). Esto permite explorar más casos de esquina y encontrar errores que los tests basados en ejemplos concretos podrían omitir. A diferencia del fuzzing puro (que solo comprueba que el programa no se rompa con inputs aleatorios), PBT valida condiciones lógicas esperadas en las salidas ([Pruebas basadas en propiedades (i) – Lambda Violet](https://lambdaviolet.wordpress.com/2018/02/13/pruebas-basadas-en-propiedades-i/#:~:text=,de%20emplearlas%20es%20muy%20reducido)). Herramientas destacadas de PBT incluyen **QuickCheck** (Haskell), que introdujo el enfoque en 2000, y numerosos puertos como ScalaCheck (JVM), FsCheck (F#/.NET) o Hypothesis (Python) ([Property-based testing con ScalaCheck. - Adictos al trabajo](https://adictosaltrabajo.com/2018/02/27/property-based-testing-con-scalacheck/#:~:text=As%C3%AD%20es%20como%20comenzaron%20a,La%20librer%C3%ADa%20se%20llam%C3%B3%20QuickCheck)) ([Property-based testing con ScalaCheck. - Adictos al trabajo](https://adictosaltrabajo.com/2018/02/27/property-based-testing-con-scalacheck/#:~:text=Esta%20herramienta%20ha%20sido%20re,C%20%C3%B3%20SwiftCheck%20para%20Swift)). A continuación se listan recursos recomendados sobre PBT, sus fundamentos teóricos, herramientas y buenas prácticas:

- **Claessen & Hughes (2000), “QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs”** – Artículo fundacional que presentó PBT ([Learning resources
](https://fscheck.github.io/FsCheck/LearningResources.html#:~:text=%2A%20,book%20is%20freely%20available%20online)). *En inglés, PDF gratis*. Es un trabajo técnico/académico avanzado que describe la biblioteca QuickCheck, la generación aleatoria de casos de test y la idea de *shrinking* (minimización de contraejemplos).  
- **Capítulo 11, _Real World Haskell_ (2008)** – Capítulo dedicado a QuickCheck ([Learning resources
](https://fscheck.github.io/FsCheck/LearningResources.html#:~:text=,programmers)), con ejemplos prácticos de PBT en Haskell. *En inglés, libre online*. Es un recurso didáctico para aprender desde cero a escribir propiedades y generadores de datos.  
- **Scott Wlaschin – “An introduction to property-based testing” (2015)** – Artículo web introductorio ([Learning resources
](https://fscheck.github.io/FsCheck/LearningResources.html#:~:text=%2A%20,book%20is%20freely%20available%20online)) que explica en términos simples qué es PBT y cómo usarlo (usando F#). *En inglés, libre online*. Muy pedagógico para iniciarse; el mismo autor tiene otro artículo, “Choosing properties for PBT” ([Learning resources
](https://fscheck.github.io/FsCheck/LearningResources.html#:~:text=%2A%20%22An%20introduction%20to%20property,by%20Scott%20Wlaschin%20link)), enfocado en buenas prácticas para identificar propiedades útiles.  
- **Fred Hebert – _Property-Based Testing with PropEr, Erlang, and Elixir_ (2019)** – Libro práctico sobre PBT aplicado a Erlang/Elixir. *En inglés, libro comercial (PragProg)* ([Learning resources
](https://fscheck.github.io/FsCheck/LearningResources.html#:~:text=Books)). Profundiza en técnicas avanzadas (ej. generación de estados, modelado de sistemas concurrentes) y está orientado a desarrolladores con interés en casos complejos.  
- **Goldstein et al. (2024), “Property-Based Testing in Practice”** – Artículo de investigación (ICSE 2024) que estudia el uso industrial de PBT mediante entrevistas ([Property-Based Testing in Practice](https://harrisongoldste.in/papers/icse24-pbt-in-practice.pdf#:~:text=ABSTRACT%20Property,in%20practice%2C%20where%20they%20see)) ([Property-Based Testing in Practice](https://harrisongoldste.in/papers/icse24-pbt-in-practice.pdf#:~:text=interviews%20provide%20empirical%20evidence%20that,impact%20areas)). *En inglés, disponible como preprint*. Resume fortalezas de PBT (excelente para probar lógica compleja y aumentar la confianza en el código) y debilidades (esfuerzo de idear buenas propiedades y generadores, dificultad para evaluar cobertura). Ofrece una visión avanzada de cómo mejorar la adopción de PBT en proyectos reales.  
- **Laura M. Castro – “Pruebas basadas en propiedades (i)” (2018)** – Artículo de blog en español que introduce PBT de forma accesible ([Pruebas basadas en propiedades (i) – Lambda Violet](https://lambdaviolet.wordpress.com/2018/02/13/pruebas-basadas-en-propiedades-i/#:~:text=En%20un%20post%20anterior%2C%20mencionamos,t%C3%A9cnica%20de%20prueba%20completamente%20aleatoria)) ([Pruebas basadas en propiedades (i) – Lambda Violet](https://lambdaviolet.wordpress.com/2018/02/13/pruebas-basadas-en-propiedades-i/#:~:text=En%20un%20punto%20intermedio%20entre,buena%20noticia%20es%20que%20las)). *En español, libre online*. Explica el concepto ubicándolo entre model checking y fuzzing, y muestra con ejemplos sencillos cómo “generar en vez de escribir” casos de prueba. Es útil como punto de partida didáctico antes de profundizar en fuentes más técnicas.  
- **Fernández, J. – *TFG: Comparativa de herramientas PBT en Python* (UDC, 2022)** – Trabajo académico (en español) que compara `hypothesis` y `Pynguin` (PyPBT) para Python. *En español, acceso abierto*. Incluye un marco teórico sobre PBT (diferencias con testing tradicional) ([Comparativa de herramientas de pruebas basadas en propiedades para el lenguaje Python](https://ruc.udc.es/dspace/handle/2183/32825#:~:text=,tipo%20de%20datos%20a%20probar)) y discute buenas prácticas al aplicar PBT en Python. Es un recurso útil para entender el estado del arte en PBT y ver recomendaciones en nuestro idioma.
 */}